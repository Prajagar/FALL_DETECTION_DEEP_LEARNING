{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./fall_dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to check if a label contains more than one class\n",
    "def contains_multiple_classes(label_file_path):\n",
    "    with open(label_file_path, \"r\") as f:\n",
    "        label_lines = f.readlines()\n",
    "        return len(label_lines) > 1\n",
    "\n",
    "# Function to delete a file\n",
    "def delete_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted: {file_path}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Load the dataset and labels\n",
    "def load_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    image_dir = os.path.join(dataset_path, \"images\",\"train\")\n",
    "    label_dir = os.path.join(dataset_path, \"labels\",\"train\")\n",
    "\n",
    "    # Set the desired image size (you can adjust this as needed)\n",
    "    image_size = (256, 256)\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        img = cv2.imread(os.path.join(image_dir, filename))\n",
    "        if img is not None:\n",
    "            img_resized = cv2.resize(img, image_size)\n",
    "\n",
    "            images.append(img_resized)\n",
    "\n",
    "            label_filename = filename[:-4] + \".txt\"\n",
    "            label_filepath = os.path.join(label_dir, label_filename)\n",
    "\n",
    "            # Check if the label contains more than one class\n",
    "            \n",
    "            with open(label_filepath, \"r\") as f:\n",
    "                label_values = [float(value) for value in f.readline().split()]\n",
    "\n",
    "                # Convert class 2 to class 1\n",
    "                if label_values[0] == 2:\n",
    "                    label_values[0] = 1\n",
    "\n",
    "                # Convert multi-class to binary labels\n",
    "                if label_values[0] == 1:\n",
    "                    labels.append([1.0])  # Not Fallen class\n",
    "                else:\n",
    "                    labels.append([0.0])  # Fallen class\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load the dataset\n",
    "images, labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "def preprocess_dataset(images, labels, test_size=0.2):\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "    # Extract class labels from bounding box information\n",
    "    y_train_classes = y_train[:, 0].astype('int')\n",
    "    y_test_classes = y_test[:, 0].astype('int')\n",
    "\n",
    "    return X_train, X_test, y_train_classes, y_test_classes\n",
    "\n",
    "# Preprocess the dataset\n",
    "X_train, X_test, y_train_classes, y_test_classes = preprocess_dataset(images, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "def augment_dataset(X_train):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    return datagen\n",
    "\n",
    "# Data Augmentation\n",
    "data_augmentor = augment_dataset(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 115200)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                7372864   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,466,242\n",
      "Trainable params: 7,466,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model for fall detection\n",
    "def create_fall_detection_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Set the input shape and number of classes\n",
    "input_shape = X_train[0].shape\n",
    "num_classes = 2  # Two classes: Fall and Non-Fall\n",
    "\n",
    "# Create the model\n",
    "model = create_fall_detection_model(input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "8/8 [==============================] - 2s 168ms/step - loss: 0.4612 - accuracy: 0.7734 - val_loss: 0.6341 - val_accuracy: 0.7059\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3959 - accuracy: 0.8270 - val_loss: 0.6953 - val_accuracy: 0.6765\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.4297 - accuracy: 0.7975 - val_loss: 0.6644 - val_accuracy: 0.7059\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.4470 - accuracy: 0.7722 - val_loss: 0.6362 - val_accuracy: 0.7059\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 1s 189ms/step - loss: 0.4474 - accuracy: 0.8101 - val_loss: 0.6419 - val_accuracy: 0.6765\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 0.4194 - accuracy: 0.8017 - val_loss: 0.6681 - val_accuracy: 0.6765\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 1s 195ms/step - loss: 0.4172 - accuracy: 0.8143 - val_loss: 0.6833 - val_accuracy: 0.6765\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.3727 - accuracy: 0.8101 - val_loss: 0.7781 - val_accuracy: 0.6471\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 2s 313ms/step - loss: 0.3852 - accuracy: 0.8270 - val_loss: 0.7767 - val_accuracy: 0.6618\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 3s 328ms/step - loss: 0.3733 - accuracy: 0.8059 - val_loss: 0.7157 - val_accuracy: 0.6618\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 3s 393ms/step - loss: 0.4219 - accuracy: 0.8101 - val_loss: 0.7624 - val_accuracy: 0.6618\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 3s 371ms/step - loss: 0.4424 - accuracy: 0.8143 - val_loss: 0.7211 - val_accuracy: 0.6471\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 3s 365ms/step - loss: 0.4111 - accuracy: 0.8101 - val_loss: 0.7443 - val_accuracy: 0.6765\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 3s 420ms/step - loss: 0.4220 - accuracy: 0.8101 - val_loss: 0.6273 - val_accuracy: 0.5882\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 3s 373ms/step - loss: 0.4016 - accuracy: 0.8228 - val_loss: 0.6943 - val_accuracy: 0.6471\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 3s 379ms/step - loss: 0.4003 - accuracy: 0.7975 - val_loss: 0.7409 - val_accuracy: 0.6618\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 3s 377ms/step - loss: 0.3687 - accuracy: 0.8186 - val_loss: 0.7553 - val_accuracy: 0.6765\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 3s 409ms/step - loss: 0.4459 - accuracy: 0.7969 - val_loss: 0.7131 - val_accuracy: 0.6912\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 3s 394ms/step - loss: 0.3976 - accuracy: 0.8312 - val_loss: 0.6353 - val_accuracy: 0.6765\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 3s 340ms/step - loss: 0.3857 - accuracy: 0.7975 - val_loss: 0.7253 - val_accuracy: 0.6324\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 2s 158ms/step - loss: 0.3563 - accuracy: 0.8481 - val_loss: 0.7388 - val_accuracy: 0.6618\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3468 - accuracy: 0.8439 - val_loss: 0.7938 - val_accuracy: 0.6765\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.3496 - accuracy: 0.8228 - val_loss: 0.8436 - val_accuracy: 0.6324\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.4217 - accuracy: 0.8228 - val_loss: 0.6492 - val_accuracy: 0.7059\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.3853 - accuracy: 0.8481 - val_loss: 0.6492 - val_accuracy: 0.7500\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.3726 - accuracy: 0.8354 - val_loss: 0.6937 - val_accuracy: 0.6618\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.3712 - accuracy: 0.8228 - val_loss: 0.7030 - val_accuracy: 0.6471\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.3736 - accuracy: 0.8312 - val_loss: 0.7578 - val_accuracy: 0.6912\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.3518 - accuracy: 0.8565 - val_loss: 0.7279 - val_accuracy: 0.6471\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.3712 - accuracy: 0.8354 - val_loss: 0.6937 - val_accuracy: 0.6912\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3252 - accuracy: 0.8439 - val_loss: 0.7881 - val_accuracy: 0.6176\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3647 - accuracy: 0.8186 - val_loss: 0.8530 - val_accuracy: 0.6471\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.3336 - accuracy: 0.8565 - val_loss: 0.7123 - val_accuracy: 0.6912\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 0.3369 - accuracy: 0.8650 - val_loss: 0.7579 - val_accuracy: 0.6765\n",
      "Epoch 35/500\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 0.3129 - accuracy: 0.8565 - val_loss: 0.6319 - val_accuracy: 0.6029\n",
      "Epoch 36/500\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.3155 - accuracy: 0.8565 - val_loss: 0.8748 - val_accuracy: 0.6618\n",
      "Epoch 37/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2768 - accuracy: 0.8692 - val_loss: 0.8488 - val_accuracy: 0.6471\n",
      "Epoch 38/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2701 - accuracy: 0.8650 - val_loss: 0.7643 - val_accuracy: 0.6912\n",
      "Epoch 39/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.3266 - accuracy: 0.8650 - val_loss: 0.6724 - val_accuracy: 0.6765\n",
      "Epoch 40/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.3065 - accuracy: 0.8776 - val_loss: 0.6855 - val_accuracy: 0.6471\n",
      "Epoch 41/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2886 - accuracy: 0.8439 - val_loss: 0.7245 - val_accuracy: 0.7059\n",
      "Epoch 42/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2910 - accuracy: 0.8692 - val_loss: 0.7554 - val_accuracy: 0.7353\n",
      "Epoch 43/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3634 - accuracy: 0.8439 - val_loss: 0.7203 - val_accuracy: 0.7353\n",
      "Epoch 44/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3111 - accuracy: 0.8565 - val_loss: 0.6773 - val_accuracy: 0.7059\n",
      "Epoch 45/500\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.3503 - accuracy: 0.8228 - val_loss: 0.8409 - val_accuracy: 0.6912\n",
      "Epoch 46/500\n",
      "8/8 [==============================] - 1s 184ms/step - loss: 0.3064 - accuracy: 0.8650 - val_loss: 0.6075 - val_accuracy: 0.7059\n",
      "Epoch 47/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2965 - accuracy: 0.8776 - val_loss: 0.8041 - val_accuracy: 0.6912\n",
      "Epoch 48/500\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.3226 - accuracy: 0.8565 - val_loss: 0.8499 - val_accuracy: 0.6912\n",
      "Epoch 49/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.2882 - accuracy: 0.8819 - val_loss: 0.7133 - val_accuracy: 0.6912\n",
      "Epoch 50/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.3677 - accuracy: 0.8312 - val_loss: 0.7967 - val_accuracy: 0.7206\n",
      "Epoch 51/500\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 0.3514 - accuracy: 0.8143 - val_loss: 0.7262 - val_accuracy: 0.7206\n",
      "Epoch 52/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.3366 - accuracy: 0.8397 - val_loss: 0.8213 - val_accuracy: 0.6618\n",
      "Epoch 53/500\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 0.3730 - accuracy: 0.8354 - val_loss: 0.6474 - val_accuracy: 0.7353\n",
      "Epoch 54/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2871 - accuracy: 0.8903 - val_loss: 0.7758 - val_accuracy: 0.7206\n",
      "Epoch 55/500\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.3248 - accuracy: 0.8776 - val_loss: 0.7656 - val_accuracy: 0.7206\n",
      "Epoch 56/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.3000 - accuracy: 0.8776 - val_loss: 0.8082 - val_accuracy: 0.6912\n",
      "Epoch 57/500\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.2852 - accuracy: 0.8906 - val_loss: 0.7822 - val_accuracy: 0.6471\n",
      "Epoch 58/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2816 - accuracy: 0.8861 - val_loss: 0.7245 - val_accuracy: 0.6765\n",
      "Epoch 59/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3395 - accuracy: 0.8692 - val_loss: 0.7894 - val_accuracy: 0.7059\n",
      "Epoch 60/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.3038 - accuracy: 0.8734 - val_loss: 0.7918 - val_accuracy: 0.6912\n",
      "Epoch 61/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.3427 - accuracy: 0.8523 - val_loss: 0.6985 - val_accuracy: 0.6471\n",
      "Epoch 62/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3219 - accuracy: 0.8692 - val_loss: 0.6510 - val_accuracy: 0.6618\n",
      "Epoch 63/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2554 - accuracy: 0.9072 - val_loss: 0.7020 - val_accuracy: 0.6912\n",
      "Epoch 64/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3171 - accuracy: 0.8861 - val_loss: 0.8336 - val_accuracy: 0.6912\n",
      "Epoch 65/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.3133 - accuracy: 0.8734 - val_loss: 0.7731 - val_accuracy: 0.6912\n",
      "Epoch 66/500\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 0.2600 - accuracy: 0.8750 - val_loss: 0.8193 - val_accuracy: 0.7059\n",
      "Epoch 67/500\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.2906 - accuracy: 0.8776 - val_loss: 0.6666 - val_accuracy: 0.6618\n",
      "Epoch 68/500\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.2488 - accuracy: 0.8945 - val_loss: 0.9129 - val_accuracy: 0.6765\n",
      "Epoch 69/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2656 - accuracy: 0.8903 - val_loss: 0.7287 - val_accuracy: 0.6765\n",
      "Epoch 70/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2898 - accuracy: 0.8692 - val_loss: 0.8913 - val_accuracy: 0.6765\n",
      "Epoch 71/500\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.2715 - accuracy: 0.8828 - val_loss: 0.7633 - val_accuracy: 0.6324\n",
      "Epoch 72/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2231 - accuracy: 0.8861 - val_loss: 0.8827 - val_accuracy: 0.5882\n",
      "Epoch 73/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.3073 - accuracy: 0.8734 - val_loss: 0.7771 - val_accuracy: 0.6176\n",
      "Epoch 74/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2282 - accuracy: 0.8987 - val_loss: 0.7836 - val_accuracy: 0.7059\n",
      "Epoch 75/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.3115 - accuracy: 0.8861 - val_loss: 0.8269 - val_accuracy: 0.6618\n",
      "Epoch 76/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.3125 - accuracy: 0.8650 - val_loss: 0.8017 - val_accuracy: 0.6618\n",
      "Epoch 77/500\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.2337 - accuracy: 0.9023 - val_loss: 0.6833 - val_accuracy: 0.6765\n",
      "Epoch 78/500\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.2804 - accuracy: 0.8861 - val_loss: 0.7962 - val_accuracy: 0.6912\n",
      "Epoch 79/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.2594 - accuracy: 0.9198 - val_loss: 0.7499 - val_accuracy: 0.6618\n",
      "Epoch 80/500\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.2686 - accuracy: 0.8903 - val_loss: 0.8157 - val_accuracy: 0.6618\n",
      "Epoch 81/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2578 - accuracy: 0.9114 - val_loss: 0.7230 - val_accuracy: 0.6471\n",
      "Epoch 82/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2469 - accuracy: 0.8776 - val_loss: 0.6707 - val_accuracy: 0.7206\n",
      "Epoch 83/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2494 - accuracy: 0.8776 - val_loss: 0.8094 - val_accuracy: 0.7206\n",
      "Epoch 84/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.3203 - accuracy: 0.8650 - val_loss: 0.8118 - val_accuracy: 0.6618\n",
      "Epoch 85/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2894 - accuracy: 0.8776 - val_loss: 0.7280 - val_accuracy: 0.6618\n",
      "Epoch 86/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.2812 - accuracy: 0.8819 - val_loss: 0.7693 - val_accuracy: 0.6471\n",
      "Epoch 87/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2898 - accuracy: 0.8565 - val_loss: 0.6746 - val_accuracy: 0.6912\n",
      "Epoch 88/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.3346 - accuracy: 0.8776 - val_loss: 0.7660 - val_accuracy: 0.6618\n",
      "Epoch 89/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.2474 - accuracy: 0.8903 - val_loss: 0.7931 - val_accuracy: 0.7353\n",
      "Epoch 90/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.2332 - accuracy: 0.8987 - val_loss: 0.8718 - val_accuracy: 0.6618\n",
      "Epoch 91/500\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.2596 - accuracy: 0.9141 - val_loss: 0.7166 - val_accuracy: 0.6765\n",
      "Epoch 92/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2408 - accuracy: 0.8987 - val_loss: 0.6377 - val_accuracy: 0.6912\n",
      "Epoch 93/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2496 - accuracy: 0.9030 - val_loss: 0.6798 - val_accuracy: 0.7059\n",
      "Epoch 94/500\n",
      "8/8 [==============================] - 1s 183ms/step - loss: 0.2583 - accuracy: 0.8903 - val_loss: 0.7795 - val_accuracy: 0.6765\n",
      "Epoch 95/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2860 - accuracy: 0.8734 - val_loss: 0.7422 - val_accuracy: 0.6765\n",
      "Epoch 96/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.1836 - accuracy: 0.9241 - val_loss: 0.8756 - val_accuracy: 0.6912\n",
      "Epoch 97/500\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.1912 - accuracy: 0.9072 - val_loss: 0.7791 - val_accuracy: 0.7059\n",
      "Epoch 98/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.2628 - accuracy: 0.8945 - val_loss: 0.7892 - val_accuracy: 0.6471\n",
      "Epoch 99/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2975 - accuracy: 0.8861 - val_loss: 0.9858 - val_accuracy: 0.6765\n",
      "Epoch 100/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.2769 - accuracy: 0.8776 - val_loss: 0.6377 - val_accuracy: 0.6618\n",
      "Epoch 101/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2754 - accuracy: 0.9072 - val_loss: 0.6430 - val_accuracy: 0.6912\n",
      "Epoch 102/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.2781 - accuracy: 0.8776 - val_loss: 0.6995 - val_accuracy: 0.6912\n",
      "Epoch 103/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2815 - accuracy: 0.8861 - val_loss: 0.7312 - val_accuracy: 0.7059\n",
      "Epoch 104/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2081 - accuracy: 0.8945 - val_loss: 0.8672 - val_accuracy: 0.6912\n",
      "Epoch 105/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.2551 - accuracy: 0.8903 - val_loss: 0.9808 - val_accuracy: 0.6912\n",
      "Epoch 106/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.2463 - accuracy: 0.8903 - val_loss: 0.9061 - val_accuracy: 0.6765\n",
      "Epoch 107/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2075 - accuracy: 0.8861 - val_loss: 0.9758 - val_accuracy: 0.6324\n",
      "Epoch 108/500\n",
      "8/8 [==============================] - 1s 184ms/step - loss: 0.2158 - accuracy: 0.9030 - val_loss: 0.9822 - val_accuracy: 0.6471\n",
      "Epoch 109/500\n",
      "8/8 [==============================] - 1s 184ms/step - loss: 0.2394 - accuracy: 0.9030 - val_loss: 0.7813 - val_accuracy: 0.6324\n",
      "Epoch 110/500\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.2434 - accuracy: 0.9072 - val_loss: 0.7768 - val_accuracy: 0.6765\n",
      "Epoch 111/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2489 - accuracy: 0.8903 - val_loss: 0.9876 - val_accuracy: 0.6471\n",
      "Epoch 112/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.3212 - accuracy: 0.8523 - val_loss: 0.7017 - val_accuracy: 0.6618\n",
      "Epoch 113/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.2866 - accuracy: 0.8861 - val_loss: 0.7101 - val_accuracy: 0.6912\n",
      "Epoch 114/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.2522 - accuracy: 0.8903 - val_loss: 0.6871 - val_accuracy: 0.7353\n",
      "Epoch 115/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.2371 - accuracy: 0.9030 - val_loss: 0.7368 - val_accuracy: 0.7059\n",
      "Epoch 116/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.2208 - accuracy: 0.9030 - val_loss: 0.6946 - val_accuracy: 0.7647\n",
      "Epoch 117/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2097 - accuracy: 0.9198 - val_loss: 0.8703 - val_accuracy: 0.6618\n",
      "Epoch 118/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2017 - accuracy: 0.9156 - val_loss: 0.7694 - val_accuracy: 0.6912\n",
      "Epoch 119/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.2047 - accuracy: 0.9283 - val_loss: 0.9019 - val_accuracy: 0.6324\n",
      "Epoch 120/500\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.2646 - accuracy: 0.9198 - val_loss: 0.9729 - val_accuracy: 0.6471\n",
      "Epoch 121/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.2158 - accuracy: 0.8819 - val_loss: 0.8718 - val_accuracy: 0.6765\n",
      "Epoch 122/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.2378 - accuracy: 0.9062 - val_loss: 0.9423 - val_accuracy: 0.7059\n",
      "Epoch 123/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2084 - accuracy: 0.9030 - val_loss: 0.9373 - val_accuracy: 0.6912\n",
      "Epoch 124/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.2491 - accuracy: 0.9156 - val_loss: 0.7450 - val_accuracy: 0.7500\n",
      "Epoch 125/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2004 - accuracy: 0.9198 - val_loss: 0.8447 - val_accuracy: 0.6765\n",
      "Epoch 126/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1806 - accuracy: 0.9198 - val_loss: 0.7874 - val_accuracy: 0.7500\n",
      "Epoch 127/500\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.2702 - accuracy: 0.8776 - val_loss: 1.1078 - val_accuracy: 0.6618\n",
      "Epoch 128/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2219 - accuracy: 0.8987 - val_loss: 0.7963 - val_accuracy: 0.7059\n",
      "Epoch 129/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1713 - accuracy: 0.9451 - val_loss: 0.8648 - val_accuracy: 0.6618\n",
      "Epoch 130/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.2018 - accuracy: 0.9241 - val_loss: 0.9924 - val_accuracy: 0.6471\n",
      "Epoch 131/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.2370 - accuracy: 0.8945 - val_loss: 0.7745 - val_accuracy: 0.6765\n",
      "Epoch 132/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.2258 - accuracy: 0.9156 - val_loss: 0.6854 - val_accuracy: 0.6324\n",
      "Epoch 133/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2405 - accuracy: 0.9030 - val_loss: 0.6913 - val_accuracy: 0.6324\n",
      "Epoch 134/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2370 - accuracy: 0.9114 - val_loss: 0.8038 - val_accuracy: 0.6324\n",
      "Epoch 135/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2384 - accuracy: 0.9030 - val_loss: 0.9749 - val_accuracy: 0.6618\n",
      "Epoch 136/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2209 - accuracy: 0.8903 - val_loss: 0.8608 - val_accuracy: 0.6765\n",
      "Epoch 137/500\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 0.1848 - accuracy: 0.9258 - val_loss: 1.1441 - val_accuracy: 0.6618\n",
      "Epoch 138/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.2348 - accuracy: 0.9156 - val_loss: 1.0399 - val_accuracy: 0.6765\n",
      "Epoch 139/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1686 - accuracy: 0.9198 - val_loss: 0.9165 - val_accuracy: 0.7353\n",
      "Epoch 140/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.1575 - accuracy: 0.9297 - val_loss: 0.8311 - val_accuracy: 0.6471\n",
      "Epoch 141/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1717 - accuracy: 0.9283 - val_loss: 0.8694 - val_accuracy: 0.6912\n",
      "Epoch 142/500\n",
      "8/8 [==============================] - 1s 189ms/step - loss: 0.1836 - accuracy: 0.9156 - val_loss: 0.8123 - val_accuracy: 0.6618\n",
      "Epoch 143/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.2631 - accuracy: 0.9030 - val_loss: 0.8887 - val_accuracy: 0.7206\n",
      "Epoch 144/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.2806 - accuracy: 0.8776 - val_loss: 0.9024 - val_accuracy: 0.7353\n",
      "Epoch 145/500\n",
      "8/8 [==============================] - 2s 181ms/step - loss: 0.2113 - accuracy: 0.9062 - val_loss: 0.9399 - val_accuracy: 0.7059\n",
      "Epoch 146/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.2325 - accuracy: 0.9156 - val_loss: 0.7827 - val_accuracy: 0.7059\n",
      "Epoch 147/500\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.2112 - accuracy: 0.9072 - val_loss: 0.7886 - val_accuracy: 0.7353\n",
      "Epoch 148/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2227 - accuracy: 0.8987 - val_loss: 0.9644 - val_accuracy: 0.7059\n",
      "Epoch 149/500\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.1587 - accuracy: 0.9325 - val_loss: 0.9880 - val_accuracy: 0.6765\n",
      "Epoch 150/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1731 - accuracy: 0.9367 - val_loss: 0.8916 - val_accuracy: 0.7206\n",
      "Epoch 151/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1952 - accuracy: 0.9198 - val_loss: 1.0512 - val_accuracy: 0.7206\n",
      "Epoch 152/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2239 - accuracy: 0.8987 - val_loss: 0.8685 - val_accuracy: 0.6765\n",
      "Epoch 153/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1870 - accuracy: 0.9114 - val_loss: 0.8650 - val_accuracy: 0.6618\n",
      "Epoch 154/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.2276 - accuracy: 0.9156 - val_loss: 0.8280 - val_accuracy: 0.7059\n",
      "Epoch 155/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.2225 - accuracy: 0.9114 - val_loss: 1.0104 - val_accuracy: 0.6618\n",
      "Epoch 156/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1687 - accuracy: 0.9325 - val_loss: 0.8677 - val_accuracy: 0.6618\n",
      "Epoch 157/500\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.1254 - accuracy: 0.9492 - val_loss: 1.0728 - val_accuracy: 0.6618\n",
      "Epoch 158/500\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.1757 - accuracy: 0.9258 - val_loss: 0.8412 - val_accuracy: 0.6912\n",
      "Epoch 159/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1835 - accuracy: 0.9241 - val_loss: 1.1910 - val_accuracy: 0.6765\n",
      "Epoch 160/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1282 - accuracy: 0.9409 - val_loss: 1.0866 - val_accuracy: 0.6618\n",
      "Epoch 161/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1221 - accuracy: 0.9494 - val_loss: 1.1743 - val_accuracy: 0.6765\n",
      "Epoch 162/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1717 - accuracy: 0.9325 - val_loss: 0.9280 - val_accuracy: 0.6765\n",
      "Epoch 163/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1892 - accuracy: 0.9367 - val_loss: 0.9419 - val_accuracy: 0.6765\n",
      "Epoch 164/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1665 - accuracy: 0.9198 - val_loss: 1.0147 - val_accuracy: 0.6324\n",
      "Epoch 165/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1483 - accuracy: 0.9367 - val_loss: 0.9884 - val_accuracy: 0.7206\n",
      "Epoch 166/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1508 - accuracy: 0.9283 - val_loss: 0.8918 - val_accuracy: 0.6765\n",
      "Epoch 167/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.1738 - accuracy: 0.9180 - val_loss: 0.8690 - val_accuracy: 0.7206\n",
      "Epoch 168/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1200 - accuracy: 0.9494 - val_loss: 1.0858 - val_accuracy: 0.6765\n",
      "Epoch 169/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1651 - accuracy: 0.9283 - val_loss: 0.9428 - val_accuracy: 0.6471\n",
      "Epoch 170/500\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.1471 - accuracy: 0.9409 - val_loss: 0.8989 - val_accuracy: 0.6618\n",
      "Epoch 171/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1806 - accuracy: 0.9241 - val_loss: 0.8810 - val_accuracy: 0.6471\n",
      "Epoch 172/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1790 - accuracy: 0.9409 - val_loss: 1.1036 - val_accuracy: 0.6471\n",
      "Epoch 173/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.2278 - accuracy: 0.8987 - val_loss: 0.8168 - val_accuracy: 0.6618\n",
      "Epoch 174/500\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 0.1586 - accuracy: 0.9375 - val_loss: 0.8217 - val_accuracy: 0.6618\n",
      "Epoch 175/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.2203 - accuracy: 0.8987 - val_loss: 0.9276 - val_accuracy: 0.6618\n",
      "Epoch 176/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1818 - accuracy: 0.9283 - val_loss: 0.8694 - val_accuracy: 0.6176\n",
      "Epoch 177/500\n",
      "8/8 [==============================] - 1s 184ms/step - loss: 0.1445 - accuracy: 0.9409 - val_loss: 0.9299 - val_accuracy: 0.6471\n",
      "Epoch 178/500\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.1297 - accuracy: 0.9536 - val_loss: 1.0494 - val_accuracy: 0.6765\n",
      "Epoch 179/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.1886 - accuracy: 0.9283 - val_loss: 1.5243 - val_accuracy: 0.6471\n",
      "Epoch 180/500\n",
      "8/8 [==============================] - 1s 184ms/step - loss: 0.2300 - accuracy: 0.9198 - val_loss: 0.8148 - val_accuracy: 0.7059\n",
      "Epoch 181/500\n",
      "8/8 [==============================] - 1s 183ms/step - loss: 0.2450 - accuracy: 0.9030 - val_loss: 0.8225 - val_accuracy: 0.6176\n",
      "Epoch 182/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2136 - accuracy: 0.9114 - val_loss: 0.7230 - val_accuracy: 0.7059\n",
      "Epoch 183/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1603 - accuracy: 0.9283 - val_loss: 0.8064 - val_accuracy: 0.7206\n",
      "Epoch 184/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.1122 - accuracy: 0.9536 - val_loss: 1.0784 - val_accuracy: 0.6765\n",
      "Epoch 185/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1407 - accuracy: 0.9367 - val_loss: 1.2055 - val_accuracy: 0.7353\n",
      "Epoch 186/500\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.1208 - accuracy: 0.9451 - val_loss: 1.2278 - val_accuracy: 0.6765\n",
      "Epoch 187/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1900 - accuracy: 0.9114 - val_loss: 1.1682 - val_accuracy: 0.6618\n",
      "Epoch 188/500\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.1586 - accuracy: 0.9336 - val_loss: 1.0741 - val_accuracy: 0.6618\n",
      "Epoch 189/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.0948 - accuracy: 0.9578 - val_loss: 0.9105 - val_accuracy: 0.6471\n",
      "Epoch 190/500\n",
      "8/8 [==============================] - 1s 182ms/step - loss: 0.1717 - accuracy: 0.9283 - val_loss: 0.8459 - val_accuracy: 0.6471\n",
      "Epoch 191/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.1652 - accuracy: 0.9451 - val_loss: 0.7353 - val_accuracy: 0.6912\n",
      "Epoch 192/500\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.1936 - accuracy: 0.9114 - val_loss: 0.8647 - val_accuracy: 0.6765\n",
      "Epoch 193/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1303 - accuracy: 0.9451 - val_loss: 1.1103 - val_accuracy: 0.6912\n",
      "Epoch 194/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.1601 - accuracy: 0.9494 - val_loss: 1.1743 - val_accuracy: 0.7206\n",
      "Epoch 195/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.1919 - accuracy: 0.9325 - val_loss: 0.8181 - val_accuracy: 0.7500\n",
      "Epoch 196/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.1970 - accuracy: 0.9241 - val_loss: 0.8741 - val_accuracy: 0.6471\n",
      "Epoch 197/500\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 0.1790 - accuracy: 0.9062 - val_loss: 0.9177 - val_accuracy: 0.6618\n",
      "Epoch 198/500\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.1702 - accuracy: 0.9297 - val_loss: 0.8934 - val_accuracy: 0.6765\n",
      "Epoch 199/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.1130 - accuracy: 0.9494 - val_loss: 1.0463 - val_accuracy: 0.7206\n",
      "Epoch 200/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1241 - accuracy: 0.9451 - val_loss: 1.2798 - val_accuracy: 0.7206\n",
      "Epoch 201/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2797 - accuracy: 0.9114 - val_loss: 0.7651 - val_accuracy: 0.6765\n",
      "Epoch 202/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.2701 - accuracy: 0.8861 - val_loss: 0.7399 - val_accuracy: 0.6176\n",
      "Epoch 203/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2535 - accuracy: 0.9156 - val_loss: 0.8094 - val_accuracy: 0.6912\n",
      "Epoch 204/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.2516 - accuracy: 0.8734 - val_loss: 0.7857 - val_accuracy: 0.6618\n",
      "Epoch 205/500\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.3019 - accuracy: 0.8672 - val_loss: 1.0061 - val_accuracy: 0.7059\n",
      "Epoch 206/500\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.2526 - accuracy: 0.8903 - val_loss: 1.0787 - val_accuracy: 0.6912\n",
      "Epoch 207/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.2631 - accuracy: 0.8945 - val_loss: 0.6548 - val_accuracy: 0.6912\n",
      "Epoch 208/500\n",
      "8/8 [==============================] - 2s 191ms/step - loss: 0.2792 - accuracy: 0.8945 - val_loss: 0.7846 - val_accuracy: 0.7059\n",
      "Epoch 209/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2277 - accuracy: 0.9072 - val_loss: 1.1179 - val_accuracy: 0.6471\n",
      "Epoch 210/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2882 - accuracy: 0.8776 - val_loss: 0.8783 - val_accuracy: 0.7059\n",
      "Epoch 211/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2867 - accuracy: 0.8903 - val_loss: 0.5591 - val_accuracy: 0.7059\n",
      "Epoch 212/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2838 - accuracy: 0.8945 - val_loss: 0.6608 - val_accuracy: 0.7353\n",
      "Epoch 213/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.2030 - accuracy: 0.9241 - val_loss: 0.7371 - val_accuracy: 0.6912\n",
      "Epoch 214/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2073 - accuracy: 0.9241 - val_loss: 0.7178 - val_accuracy: 0.7059\n",
      "Epoch 215/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.2105 - accuracy: 0.8987 - val_loss: 0.8163 - val_accuracy: 0.6912\n",
      "Epoch 216/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.1413 - accuracy: 0.9451 - val_loss: 0.8166 - val_accuracy: 0.6912\n",
      "Epoch 217/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1395 - accuracy: 0.9451 - val_loss: 0.8223 - val_accuracy: 0.7059\n",
      "Epoch 218/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1954 - accuracy: 0.9156 - val_loss: 0.6393 - val_accuracy: 0.7206\n",
      "Epoch 219/500\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 0.1704 - accuracy: 0.9336 - val_loss: 0.6318 - val_accuracy: 0.6912\n",
      "Epoch 220/500\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.2162 - accuracy: 0.9241 - val_loss: 0.6049 - val_accuracy: 0.7206\n",
      "Epoch 221/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1761 - accuracy: 0.9283 - val_loss: 0.8889 - val_accuracy: 0.7059\n",
      "Epoch 222/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1836 - accuracy: 0.9283 - val_loss: 0.8873 - val_accuracy: 0.7206\n",
      "Epoch 223/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1730 - accuracy: 0.9198 - val_loss: 0.8217 - val_accuracy: 0.7206\n",
      "Epoch 224/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1229 - accuracy: 0.9536 - val_loss: 0.7419 - val_accuracy: 0.7206\n",
      "Epoch 225/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1166 - accuracy: 0.9325 - val_loss: 0.8649 - val_accuracy: 0.7500\n",
      "Epoch 226/500\n",
      "8/8 [==============================] - 1s 184ms/step - loss: 0.1622 - accuracy: 0.9283 - val_loss: 0.8310 - val_accuracy: 0.7059\n",
      "Epoch 227/500\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.1429 - accuracy: 0.9367 - val_loss: 0.8639 - val_accuracy: 0.6912\n",
      "Epoch 228/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1463 - accuracy: 0.9367 - val_loss: 0.9551 - val_accuracy: 0.6765\n",
      "Epoch 229/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.2417 - accuracy: 0.9114 - val_loss: 0.9719 - val_accuracy: 0.6471\n",
      "Epoch 230/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.1639 - accuracy: 0.9241 - val_loss: 0.9245 - val_accuracy: 0.7059\n",
      "Epoch 231/500\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.1407 - accuracy: 0.9453 - val_loss: 0.8871 - val_accuracy: 0.6765\n",
      "Epoch 232/500\n",
      "8/8 [==============================] - 2s 177ms/step - loss: 0.1392 - accuracy: 0.9531 - val_loss: 0.8620 - val_accuracy: 0.7206\n",
      "Epoch 233/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.1913 - accuracy: 0.9367 - val_loss: 0.8485 - val_accuracy: 0.7059\n",
      "Epoch 234/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.1477 - accuracy: 0.9451 - val_loss: 0.8238 - val_accuracy: 0.7353\n",
      "Epoch 235/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1657 - accuracy: 0.9156 - val_loss: 0.8261 - val_accuracy: 0.7353\n",
      "Epoch 236/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1392 - accuracy: 0.9367 - val_loss: 0.7748 - val_accuracy: 0.7206\n",
      "Epoch 237/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1418 - accuracy: 0.9409 - val_loss: 0.8684 - val_accuracy: 0.7206\n",
      "Epoch 238/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1113 - accuracy: 0.9662 - val_loss: 0.8934 - val_accuracy: 0.6912\n",
      "Epoch 239/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1175 - accuracy: 0.9536 - val_loss: 0.8242 - val_accuracy: 0.6765\n",
      "Epoch 240/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1882 - accuracy: 0.9114 - val_loss: 0.8120 - val_accuracy: 0.7206\n",
      "Epoch 241/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1199 - accuracy: 0.9494 - val_loss: 1.1138 - val_accuracy: 0.6471\n",
      "Epoch 242/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2090 - accuracy: 0.8945 - val_loss: 0.6926 - val_accuracy: 0.6765\n",
      "Epoch 243/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1661 - accuracy: 0.9241 - val_loss: 0.8348 - val_accuracy: 0.7059\n",
      "Epoch 244/500\n",
      "8/8 [==============================] - 1s 190ms/step - loss: 0.0915 - accuracy: 0.9578 - val_loss: 0.8279 - val_accuracy: 0.6912\n",
      "Epoch 245/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.0944 - accuracy: 0.9451 - val_loss: 0.8592 - val_accuracy: 0.6912\n",
      "Epoch 246/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1842 - accuracy: 0.9451 - val_loss: 1.0319 - val_accuracy: 0.6765\n",
      "Epoch 247/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1566 - accuracy: 0.9030 - val_loss: 0.8026 - val_accuracy: 0.7647\n",
      "Epoch 248/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1307 - accuracy: 0.9451 - val_loss: 1.0811 - val_accuracy: 0.6912\n",
      "Epoch 249/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1141 - accuracy: 0.9578 - val_loss: 1.0023 - val_accuracy: 0.6912\n",
      "Epoch 250/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.1221 - accuracy: 0.9494 - val_loss: 1.0170 - val_accuracy: 0.6912\n",
      "Epoch 251/500\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.1270 - accuracy: 0.9494 - val_loss: 1.1331 - val_accuracy: 0.6618\n",
      "Epoch 252/500\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.1083 - accuracy: 0.9494 - val_loss: 0.8811 - val_accuracy: 0.7059\n",
      "Epoch 253/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.1043 - accuracy: 0.9494 - val_loss: 1.1181 - val_accuracy: 0.6765\n",
      "Epoch 254/500\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.1465 - accuracy: 0.9283 - val_loss: 1.1933 - val_accuracy: 0.6765\n",
      "Epoch 255/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1722 - accuracy: 0.9283 - val_loss: 1.0454 - val_accuracy: 0.6324\n",
      "Epoch 256/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.1647 - accuracy: 0.9325 - val_loss: 1.2603 - val_accuracy: 0.6765\n",
      "Epoch 257/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1169 - accuracy: 0.9494 - val_loss: 0.9503 - val_accuracy: 0.7059\n",
      "Epoch 258/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.1161 - accuracy: 0.9536 - val_loss: 1.0324 - val_accuracy: 0.6765\n",
      "Epoch 259/500\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 0.1138 - accuracy: 0.9536 - val_loss: 0.9499 - val_accuracy: 0.6765\n",
      "Epoch 260/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.1483 - accuracy: 0.9494 - val_loss: 0.8079 - val_accuracy: 0.6912\n",
      "Epoch 261/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1448 - accuracy: 0.9325 - val_loss: 1.1923 - val_accuracy: 0.7353\n",
      "Epoch 262/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.2071 - accuracy: 0.9030 - val_loss: 0.7789 - val_accuracy: 0.7059\n",
      "Epoch 263/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1476 - accuracy: 0.9367 - val_loss: 1.1365 - val_accuracy: 0.6618\n",
      "Epoch 264/500\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 0.1362 - accuracy: 0.9414 - val_loss: 0.9394 - val_accuracy: 0.6765\n",
      "Epoch 265/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1807 - accuracy: 0.9325 - val_loss: 1.0114 - val_accuracy: 0.7353\n",
      "Epoch 266/500\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.1230 - accuracy: 0.9578 - val_loss: 0.9130 - val_accuracy: 0.7206\n",
      "Epoch 267/500\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 0.0983 - accuracy: 0.9536 - val_loss: 0.8885 - val_accuracy: 0.7353\n",
      "Epoch 268/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1380 - accuracy: 0.9409 - val_loss: 0.8639 - val_accuracy: 0.7059\n",
      "Epoch 269/500\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.1912 - accuracy: 0.9198 - val_loss: 0.8042 - val_accuracy: 0.7206\n",
      "Epoch 270/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1523 - accuracy: 0.9409 - val_loss: 0.7795 - val_accuracy: 0.7500\n",
      "Epoch 271/500\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 0.1357 - accuracy: 0.9453 - val_loss: 1.1305 - val_accuracy: 0.7206\n",
      "Epoch 272/500\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.1083 - accuracy: 0.9409 - val_loss: 1.0139 - val_accuracy: 0.7206\n",
      "Epoch 273/500\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.1456 - accuracy: 0.9409 - val_loss: 0.9451 - val_accuracy: 0.7059\n",
      "Epoch 274/500\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 0.1297 - accuracy: 0.9531 - val_loss: 0.8967 - val_accuracy: 0.7206\n",
      "Epoch 275/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1154 - accuracy: 0.9494 - val_loss: 0.8518 - val_accuracy: 0.6912\n",
      "Epoch 276/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1148 - accuracy: 0.9536 - val_loss: 1.0201 - val_accuracy: 0.7206\n",
      "Epoch 277/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.1152 - accuracy: 0.9492 - val_loss: 0.9638 - val_accuracy: 0.7059\n",
      "Epoch 278/500\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.1019 - accuracy: 0.9536 - val_loss: 0.8352 - val_accuracy: 0.6912\n",
      "Epoch 279/500\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 0.0792 - accuracy: 0.9570 - val_loss: 0.8233 - val_accuracy: 0.7206\n",
      "Epoch 280/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.0953 - accuracy: 0.9620 - val_loss: 0.8352 - val_accuracy: 0.6912\n",
      "Epoch 281/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1059 - accuracy: 0.9620 - val_loss: 1.0090 - val_accuracy: 0.6912\n",
      "Epoch 282/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1453 - accuracy: 0.9367 - val_loss: 1.2919 - val_accuracy: 0.6912\n",
      "Epoch 283/500\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.1504 - accuracy: 0.9241 - val_loss: 0.8604 - val_accuracy: 0.6912\n",
      "Epoch 284/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.1423 - accuracy: 0.9241 - val_loss: 0.9073 - val_accuracy: 0.6765\n",
      "Epoch 285/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.0845 - accuracy: 0.9578 - val_loss: 1.2262 - val_accuracy: 0.7206\n",
      "Epoch 286/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0856 - accuracy: 0.9662 - val_loss: 1.1960 - val_accuracy: 0.7059\n",
      "Epoch 287/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0738 - accuracy: 0.9789 - val_loss: 1.0724 - val_accuracy: 0.7206\n",
      "Epoch 288/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1772 - accuracy: 0.9283 - val_loss: 1.5220 - val_accuracy: 0.6324\n",
      "Epoch 289/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1320 - accuracy: 0.9536 - val_loss: 1.3228 - val_accuracy: 0.6912\n",
      "Epoch 290/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1648 - accuracy: 0.9494 - val_loss: 1.0491 - val_accuracy: 0.6765\n",
      "Epoch 291/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1555 - accuracy: 0.9494 - val_loss: 1.0548 - val_accuracy: 0.6765\n",
      "Epoch 292/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1385 - accuracy: 0.9451 - val_loss: 0.9357 - val_accuracy: 0.6912\n",
      "Epoch 293/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1488 - accuracy: 0.9536 - val_loss: 1.0334 - val_accuracy: 0.6765\n",
      "Epoch 294/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1305 - accuracy: 0.9367 - val_loss: 1.2022 - val_accuracy: 0.6765\n",
      "Epoch 295/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1106 - accuracy: 0.9451 - val_loss: 0.9129 - val_accuracy: 0.7059\n",
      "Epoch 296/500\n",
      "8/8 [==============================] - 1s 190ms/step - loss: 0.1211 - accuracy: 0.9451 - val_loss: 1.1033 - val_accuracy: 0.6912\n",
      "Epoch 297/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0902 - accuracy: 0.9662 - val_loss: 1.1833 - val_accuracy: 0.6618\n",
      "Epoch 298/500\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.0798 - accuracy: 0.9620 - val_loss: 1.0486 - val_accuracy: 0.6618\n",
      "Epoch 299/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0813 - accuracy: 0.9705 - val_loss: 0.8910 - val_accuracy: 0.6765\n",
      "Epoch 300/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1049 - accuracy: 0.9578 - val_loss: 0.9189 - val_accuracy: 0.6912\n",
      "Epoch 301/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.1417 - accuracy: 0.9451 - val_loss: 1.3804 - val_accuracy: 0.7206\n",
      "Epoch 302/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.1039 - accuracy: 0.9494 - val_loss: 1.0446 - val_accuracy: 0.7059\n",
      "Epoch 303/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1300 - accuracy: 0.9578 - val_loss: 0.9443 - val_accuracy: 0.7794\n",
      "Epoch 304/500\n",
      "8/8 [==============================] - 1s 177ms/step - loss: 0.1174 - accuracy: 0.9531 - val_loss: 1.2899 - val_accuracy: 0.7059\n",
      "Epoch 305/500\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.0963 - accuracy: 0.9620 - val_loss: 0.8138 - val_accuracy: 0.6765\n",
      "Epoch 306/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1355 - accuracy: 0.9283 - val_loss: 1.1560 - val_accuracy: 0.7059\n",
      "Epoch 307/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.0891 - accuracy: 0.9620 - val_loss: 1.0751 - val_accuracy: 0.6912\n",
      "Epoch 308/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.0961 - accuracy: 0.9453 - val_loss: 0.9183 - val_accuracy: 0.7059\n",
      "Epoch 309/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1015 - accuracy: 0.9451 - val_loss: 1.1903 - val_accuracy: 0.6912\n",
      "Epoch 310/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1402 - accuracy: 0.9325 - val_loss: 0.8170 - val_accuracy: 0.7059\n",
      "Epoch 311/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1007 - accuracy: 0.9620 - val_loss: 0.7669 - val_accuracy: 0.7206\n",
      "Epoch 312/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.0980 - accuracy: 0.9536 - val_loss: 0.8538 - val_accuracy: 0.7206\n",
      "Epoch 313/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0774 - accuracy: 0.9536 - val_loss: 0.8156 - val_accuracy: 0.7500\n",
      "Epoch 314/500\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 0.1039 - accuracy: 0.9492 - val_loss: 1.0092 - val_accuracy: 0.7059\n",
      "Epoch 315/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0820 - accuracy: 0.9620 - val_loss: 1.1961 - val_accuracy: 0.6912\n",
      "Epoch 316/500\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 0.0877 - accuracy: 0.9609 - val_loss: 1.2410 - val_accuracy: 0.7059\n",
      "Epoch 317/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1044 - accuracy: 0.9578 - val_loss: 1.0629 - val_accuracy: 0.6912\n",
      "Epoch 318/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0788 - accuracy: 0.9536 - val_loss: 0.8122 - val_accuracy: 0.6765\n",
      "Epoch 319/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0757 - accuracy: 0.9747 - val_loss: 1.0596 - val_accuracy: 0.6765\n",
      "Epoch 320/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1403 - accuracy: 0.9367 - val_loss: 1.3260 - val_accuracy: 0.6912\n",
      "Epoch 321/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.1133 - accuracy: 0.9451 - val_loss: 1.5318 - val_accuracy: 0.6765\n",
      "Epoch 322/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.0833 - accuracy: 0.9648 - val_loss: 1.2842 - val_accuracy: 0.7353\n",
      "Epoch 323/500\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.1084 - accuracy: 0.9409 - val_loss: 1.9219 - val_accuracy: 0.6765\n",
      "Epoch 324/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.1262 - accuracy: 0.9536 - val_loss: 1.2163 - val_accuracy: 0.6912\n",
      "Epoch 325/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.0981 - accuracy: 0.9494 - val_loss: 1.3564 - val_accuracy: 0.7206\n",
      "Epoch 326/500\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.1092 - accuracy: 0.9578 - val_loss: 1.1483 - val_accuracy: 0.6765\n",
      "Epoch 327/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0649 - accuracy: 0.9747 - val_loss: 0.9879 - val_accuracy: 0.6912\n",
      "Epoch 328/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.0869 - accuracy: 0.9620 - val_loss: 1.0759 - val_accuracy: 0.6765\n",
      "Epoch 329/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.1016 - accuracy: 0.9531 - val_loss: 1.3724 - val_accuracy: 0.7353\n",
      "Epoch 330/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0897 - accuracy: 0.9662 - val_loss: 1.1609 - val_accuracy: 0.6912\n",
      "Epoch 331/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1350 - accuracy: 0.9409 - val_loss: 0.8122 - val_accuracy: 0.6765\n",
      "Epoch 332/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.1076 - accuracy: 0.9662 - val_loss: 0.9963 - val_accuracy: 0.6765\n",
      "Epoch 333/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0995 - accuracy: 0.9494 - val_loss: 1.1234 - val_accuracy: 0.7059\n",
      "Epoch 334/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0805 - accuracy: 0.9536 - val_loss: 1.0686 - val_accuracy: 0.7206\n",
      "Epoch 335/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0456 - accuracy: 0.9789 - val_loss: 1.1654 - val_accuracy: 0.7059\n",
      "Epoch 336/500\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.0605 - accuracy: 0.9766 - val_loss: 1.1499 - val_accuracy: 0.6912\n",
      "Epoch 337/500\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.1083 - accuracy: 0.9620 - val_loss: 1.4955 - val_accuracy: 0.7206\n",
      "Epoch 338/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1468 - accuracy: 0.9241 - val_loss: 0.9258 - val_accuracy: 0.7206\n",
      "Epoch 339/500\n",
      "8/8 [==============================] - 1s 189ms/step - loss: 0.1232 - accuracy: 0.9494 - val_loss: 0.9887 - val_accuracy: 0.7206\n",
      "Epoch 340/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0937 - accuracy: 0.9662 - val_loss: 0.8480 - val_accuracy: 0.7059\n",
      "Epoch 341/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1178 - accuracy: 0.9494 - val_loss: 1.1309 - val_accuracy: 0.7353\n",
      "Epoch 342/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1134 - accuracy: 0.9367 - val_loss: 0.9430 - val_accuracy: 0.6912\n",
      "Epoch 343/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.1112 - accuracy: 0.9451 - val_loss: 1.1227 - val_accuracy: 0.7059\n",
      "Epoch 344/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0827 - accuracy: 0.9578 - val_loss: 0.9669 - val_accuracy: 0.7206\n",
      "Epoch 345/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0928 - accuracy: 0.9747 - val_loss: 0.8953 - val_accuracy: 0.7206\n",
      "Epoch 346/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0778 - accuracy: 0.9747 - val_loss: 0.9860 - val_accuracy: 0.7353\n",
      "Epoch 347/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0776 - accuracy: 0.9705 - val_loss: 1.0829 - val_accuracy: 0.7206\n",
      "Epoch 348/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1451 - accuracy: 0.9367 - val_loss: 1.1770 - val_accuracy: 0.7500\n",
      "Epoch 349/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.2144 - accuracy: 0.9367 - val_loss: 1.1272 - val_accuracy: 0.7206\n",
      "Epoch 350/500\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 0.1756 - accuracy: 0.9258 - val_loss: 1.0911 - val_accuracy: 0.6912\n",
      "Epoch 351/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1693 - accuracy: 0.9198 - val_loss: 0.7560 - val_accuracy: 0.7206\n",
      "Epoch 352/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1683 - accuracy: 0.9409 - val_loss: 0.6306 - val_accuracy: 0.7647\n",
      "Epoch 353/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0871 - accuracy: 0.9620 - val_loss: 0.9497 - val_accuracy: 0.7059\n",
      "Epoch 354/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1136 - accuracy: 0.9494 - val_loss: 0.6109 - val_accuracy: 0.7500\n",
      "Epoch 355/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.1372 - accuracy: 0.9375 - val_loss: 0.8100 - val_accuracy: 0.7353\n",
      "Epoch 356/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0739 - accuracy: 0.9662 - val_loss: 0.8615 - val_accuracy: 0.6765\n",
      "Epoch 357/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.1395 - accuracy: 0.9494 - val_loss: 1.2212 - val_accuracy: 0.7206\n",
      "Epoch 358/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0561 - accuracy: 0.9789 - val_loss: 0.6908 - val_accuracy: 0.7647\n",
      "Epoch 359/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.0614 - accuracy: 0.9747 - val_loss: 0.8431 - val_accuracy: 0.7794\n",
      "Epoch 360/500\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.0916 - accuracy: 0.9620 - val_loss: 0.8686 - val_accuracy: 0.7941\n",
      "Epoch 361/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1026 - accuracy: 0.9451 - val_loss: 1.2069 - val_accuracy: 0.7500\n",
      "Epoch 362/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.0895 - accuracy: 0.9662 - val_loss: 1.0208 - val_accuracy: 0.7647\n",
      "Epoch 363/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.1179 - accuracy: 0.9494 - val_loss: 0.8835 - val_accuracy: 0.7353\n",
      "Epoch 364/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.1487 - accuracy: 0.9325 - val_loss: 1.0684 - val_accuracy: 0.7794\n",
      "Epoch 365/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0984 - accuracy: 0.9494 - val_loss: 1.2159 - val_accuracy: 0.7794\n",
      "Epoch 366/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1626 - accuracy: 0.9241 - val_loss: 1.1062 - val_accuracy: 0.7353\n",
      "Epoch 367/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1083 - accuracy: 0.9494 - val_loss: 0.8757 - val_accuracy: 0.7206\n",
      "Epoch 368/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.1403 - accuracy: 0.9283 - val_loss: 0.8451 - val_accuracy: 0.7353\n",
      "Epoch 369/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1117 - accuracy: 0.9451 - val_loss: 0.8443 - val_accuracy: 0.7353\n",
      "Epoch 370/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1270 - accuracy: 0.9536 - val_loss: 0.7152 - val_accuracy: 0.7353\n",
      "Epoch 371/500\n",
      "8/8 [==============================] - 1s 191ms/step - loss: 0.0746 - accuracy: 0.9620 - val_loss: 0.5328 - val_accuracy: 0.7206\n",
      "Epoch 372/500\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.1087 - accuracy: 0.9620 - val_loss: 0.7835 - val_accuracy: 0.7794\n",
      "Epoch 373/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1151 - accuracy: 0.9578 - val_loss: 0.7210 - val_accuracy: 0.7353\n",
      "Epoch 374/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.0767 - accuracy: 0.9747 - val_loss: 0.7421 - val_accuracy: 0.6912\n",
      "Epoch 375/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.1156 - accuracy: 0.9494 - val_loss: 0.8502 - val_accuracy: 0.7353\n",
      "Epoch 376/500\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.0710 - accuracy: 0.9705 - val_loss: 0.8305 - val_accuracy: 0.7353\n",
      "Epoch 377/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.1602 - accuracy: 0.9367 - val_loss: 0.6206 - val_accuracy: 0.7353\n",
      "Epoch 378/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.0638 - accuracy: 0.9705 - val_loss: 0.8144 - val_accuracy: 0.7500\n",
      "Epoch 379/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1411 - accuracy: 0.9536 - val_loss: 1.0147 - val_accuracy: 0.7059\n",
      "Epoch 380/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.0899 - accuracy: 0.9570 - val_loss: 0.8661 - val_accuracy: 0.7059\n",
      "Epoch 381/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0930 - accuracy: 0.9620 - val_loss: 1.1643 - val_accuracy: 0.7059\n",
      "Epoch 382/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.0690 - accuracy: 0.9747 - val_loss: 0.7391 - val_accuracy: 0.7206\n",
      "Epoch 383/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1452 - accuracy: 0.9662 - val_loss: 0.9851 - val_accuracy: 0.7206\n",
      "Epoch 384/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.0848 - accuracy: 0.9536 - val_loss: 1.0321 - val_accuracy: 0.7647\n",
      "Epoch 385/500\n",
      "8/8 [==============================] - 1s 190ms/step - loss: 0.1420 - accuracy: 0.9367 - val_loss: 0.8210 - val_accuracy: 0.7353\n",
      "Epoch 386/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.1018 - accuracy: 0.9536 - val_loss: 0.7344 - val_accuracy: 0.7206\n",
      "Epoch 387/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0767 - accuracy: 0.9578 - val_loss: 0.8415 - val_accuracy: 0.7353\n",
      "Epoch 388/500\n",
      "8/8 [==============================] - 1s 189ms/step - loss: 0.1139 - accuracy: 0.9536 - val_loss: 0.8153 - val_accuracy: 0.7500\n",
      "Epoch 389/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0903 - accuracy: 0.9578 - val_loss: 0.8536 - val_accuracy: 0.7647\n",
      "Epoch 390/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1488 - accuracy: 0.9620 - val_loss: 0.8754 - val_accuracy: 0.7353\n",
      "Epoch 391/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.1166 - accuracy: 0.9409 - val_loss: 1.1742 - val_accuracy: 0.7500\n",
      "Epoch 392/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0881 - accuracy: 0.9578 - val_loss: 0.7834 - val_accuracy: 0.7794\n",
      "Epoch 393/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1683 - accuracy: 0.9409 - val_loss: 1.0457 - val_accuracy: 0.7647\n",
      "Epoch 394/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.0957 - accuracy: 0.9662 - val_loss: 0.8446 - val_accuracy: 0.6912\n",
      "Epoch 395/500\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.1056 - accuracy: 0.9536 - val_loss: 1.1967 - val_accuracy: 0.7647\n",
      "Epoch 396/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0770 - accuracy: 0.9705 - val_loss: 1.4209 - val_accuracy: 0.7647\n",
      "Epoch 397/500\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 0.0763 - accuracy: 0.9570 - val_loss: 1.0446 - val_accuracy: 0.7500\n",
      "Epoch 398/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.1257 - accuracy: 0.9409 - val_loss: 1.5298 - val_accuracy: 0.7206\n",
      "Epoch 399/500\n",
      "8/8 [==============================] - 1s 194ms/step - loss: 0.0698 - accuracy: 0.9578 - val_loss: 1.2184 - val_accuracy: 0.7500\n",
      "Epoch 400/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1155 - accuracy: 0.9494 - val_loss: 1.0889 - val_accuracy: 0.7941\n",
      "Epoch 401/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1138 - accuracy: 0.9578 - val_loss: 1.4054 - val_accuracy: 0.7206\n",
      "Epoch 402/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1239 - accuracy: 0.9451 - val_loss: 0.8873 - val_accuracy: 0.7941\n",
      "Epoch 403/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0981 - accuracy: 0.9620 - val_loss: 1.1255 - val_accuracy: 0.7647\n",
      "Epoch 404/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0725 - accuracy: 0.9705 - val_loss: 1.2246 - val_accuracy: 0.7500\n",
      "Epoch 405/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0968 - accuracy: 0.9620 - val_loss: 1.3011 - val_accuracy: 0.7353\n",
      "Epoch 406/500\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.0881 - accuracy: 0.9494 - val_loss: 1.2962 - val_accuracy: 0.7500\n",
      "Epoch 407/500\n",
      "8/8 [==============================] - 1s 189ms/step - loss: 0.1052 - accuracy: 0.9662 - val_loss: 1.0646 - val_accuracy: 0.6912\n",
      "Epoch 408/500\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.1218 - accuracy: 0.9578 - val_loss: 0.9932 - val_accuracy: 0.6765\n",
      "Epoch 409/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0814 - accuracy: 0.9620 - val_loss: 1.0458 - val_accuracy: 0.7059\n",
      "Epoch 410/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.1495 - accuracy: 0.9414 - val_loss: 0.7126 - val_accuracy: 0.7353\n",
      "Epoch 411/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.0959 - accuracy: 0.9536 - val_loss: 1.0834 - val_accuracy: 0.7206\n",
      "Epoch 412/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.0709 - accuracy: 0.9747 - val_loss: 0.9328 - val_accuracy: 0.7206\n",
      "Epoch 413/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0818 - accuracy: 0.9620 - val_loss: 0.9912 - val_accuracy: 0.7206\n",
      "Epoch 414/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.0758 - accuracy: 0.9578 - val_loss: 1.2225 - val_accuracy: 0.7353\n",
      "Epoch 415/500\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.0814 - accuracy: 0.9620 - val_loss: 1.0205 - val_accuracy: 0.7500\n",
      "Epoch 416/500\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.0628 - accuracy: 0.9705 - val_loss: 0.9392 - val_accuracy: 0.7059\n",
      "Epoch 417/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0495 - accuracy: 0.9705 - val_loss: 1.5383 - val_accuracy: 0.7206\n",
      "Epoch 418/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0946 - accuracy: 0.9620 - val_loss: 1.3810 - val_accuracy: 0.7206\n",
      "Epoch 419/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.0407 - accuracy: 0.9766 - val_loss: 1.2311 - val_accuracy: 0.7500\n",
      "Epoch 420/500\n",
      "8/8 [==============================] - 2s 181ms/step - loss: 0.0643 - accuracy: 0.9727 - val_loss: 1.0615 - val_accuracy: 0.7353\n",
      "Epoch 421/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0842 - accuracy: 0.9789 - val_loss: 0.7474 - val_accuracy: 0.7794\n",
      "Epoch 422/500\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.0542 - accuracy: 0.9705 - val_loss: 0.8076 - val_accuracy: 0.7353\n",
      "Epoch 423/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0805 - accuracy: 0.9494 - val_loss: 1.2408 - val_accuracy: 0.7059\n",
      "Epoch 424/500\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.1135 - accuracy: 0.9494 - val_loss: 1.4381 - val_accuracy: 0.6912\n",
      "Epoch 425/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.0984 - accuracy: 0.9648 - val_loss: 1.3327 - val_accuracy: 0.6912\n",
      "Epoch 426/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.0930 - accuracy: 0.9578 - val_loss: 0.9977 - val_accuracy: 0.7059\n",
      "Epoch 427/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.0534 - accuracy: 0.9831 - val_loss: 1.2346 - val_accuracy: 0.7059\n",
      "Epoch 428/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.1007 - accuracy: 0.9536 - val_loss: 1.5677 - val_accuracy: 0.7353\n",
      "Epoch 429/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0786 - accuracy: 0.9747 - val_loss: 1.0748 - val_accuracy: 0.7647\n",
      "Epoch 430/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0778 - accuracy: 0.9578 - val_loss: 1.3727 - val_accuracy: 0.7353\n",
      "Epoch 431/500\n",
      "8/8 [==============================] - 1s 163ms/step - loss: 0.0995 - accuracy: 0.9620 - val_loss: 1.1481 - val_accuracy: 0.7353\n",
      "Epoch 432/500\n",
      "8/8 [==============================] - 1s 186ms/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 1.1088 - val_accuracy: 0.7353\n",
      "Epoch 433/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0508 - accuracy: 0.9620 - val_loss: 1.3219 - val_accuracy: 0.7206\n",
      "Epoch 434/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.0596 - accuracy: 0.9662 - val_loss: 1.0062 - val_accuracy: 0.7647\n",
      "Epoch 435/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.1003 - accuracy: 0.9494 - val_loss: 1.0476 - val_accuracy: 0.7500\n",
      "Epoch 436/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0942 - accuracy: 0.9536 - val_loss: 1.3346 - val_accuracy: 0.7059\n",
      "Epoch 437/500\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.0389 - accuracy: 0.9873 - val_loss: 1.1799 - val_accuracy: 0.7353\n",
      "Epoch 438/500\n",
      "8/8 [==============================] - 1s 190ms/step - loss: 0.0821 - accuracy: 0.9705 - val_loss: 1.1609 - val_accuracy: 0.7647\n",
      "Epoch 439/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.0604 - accuracy: 0.9747 - val_loss: 1.1637 - val_accuracy: 0.7647\n",
      "Epoch 440/500\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.0562 - accuracy: 0.9747 - val_loss: 1.7337 - val_accuracy: 0.7206\n",
      "Epoch 441/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1670 - accuracy: 0.9620 - val_loss: 0.9715 - val_accuracy: 0.7941\n",
      "Epoch 442/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1176 - accuracy: 0.9536 - val_loss: 1.2653 - val_accuracy: 0.7059\n",
      "Epoch 443/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.0593 - accuracy: 0.9747 - val_loss: 1.7109 - val_accuracy: 0.7353\n",
      "Epoch 444/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.1029 - accuracy: 0.9536 - val_loss: 0.7119 - val_accuracy: 0.7941\n",
      "Epoch 445/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0794 - accuracy: 0.9662 - val_loss: 1.0771 - val_accuracy: 0.7206\n",
      "Epoch 446/500\n",
      "8/8 [==============================] - 2s 180ms/step - loss: 0.0679 - accuracy: 0.9766 - val_loss: 0.9407 - val_accuracy: 0.6912\n",
      "Epoch 447/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0585 - accuracy: 0.9662 - val_loss: 1.2339 - val_accuracy: 0.7206\n",
      "Epoch 448/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0955 - accuracy: 0.9620 - val_loss: 1.1335 - val_accuracy: 0.7647\n",
      "Epoch 449/500\n",
      "8/8 [==============================] - 1s 176ms/step - loss: 0.0811 - accuracy: 0.9648 - val_loss: 1.1968 - val_accuracy: 0.7794\n",
      "Epoch 450/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.0927 - accuracy: 0.9578 - val_loss: 1.0325 - val_accuracy: 0.7794\n",
      "Epoch 451/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0998 - accuracy: 0.9536 - val_loss: 0.9585 - val_accuracy: 0.7059\n",
      "Epoch 452/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0544 - accuracy: 0.9705 - val_loss: 0.8666 - val_accuracy: 0.7059\n",
      "Epoch 453/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.0492 - accuracy: 0.9831 - val_loss: 0.9722 - val_accuracy: 0.6912\n",
      "Epoch 454/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0508 - accuracy: 0.9747 - val_loss: 0.9834 - val_accuracy: 0.6912\n",
      "Epoch 455/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0812 - accuracy: 0.9662 - val_loss: 0.9451 - val_accuracy: 0.6765\n",
      "Epoch 456/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0623 - accuracy: 0.9747 - val_loss: 1.0971 - val_accuracy: 0.7206\n",
      "Epoch 457/500\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 0.0756 - accuracy: 0.9570 - val_loss: 1.2584 - val_accuracy: 0.7353\n",
      "Epoch 458/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0630 - accuracy: 0.9789 - val_loss: 1.0938 - val_accuracy: 0.7647\n",
      "Epoch 459/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0518 - accuracy: 0.9831 - val_loss: 1.3073 - val_accuracy: 0.7794\n",
      "Epoch 460/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0751 - accuracy: 0.9747 - val_loss: 1.5324 - val_accuracy: 0.7353\n",
      "Epoch 461/500\n",
      "8/8 [==============================] - 2s 179ms/step - loss: 0.0594 - accuracy: 0.9648 - val_loss: 1.2333 - val_accuracy: 0.7794\n",
      "Epoch 462/500\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 0.0681 - accuracy: 0.9766 - val_loss: 1.1549 - val_accuracy: 0.7794\n",
      "Epoch 463/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0345 - accuracy: 0.9958 - val_loss: 1.0722 - val_accuracy: 0.7500\n",
      "Epoch 464/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0893 - accuracy: 0.9620 - val_loss: 1.3123 - val_accuracy: 0.7353\n",
      "Epoch 465/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0720 - accuracy: 0.9662 - val_loss: 1.3757 - val_accuracy: 0.7059\n",
      "Epoch 466/500\n",
      "8/8 [==============================] - 1s 173ms/step - loss: 0.0707 - accuracy: 0.9789 - val_loss: 0.8037 - val_accuracy: 0.7353\n",
      "Epoch 467/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0848 - accuracy: 0.9494 - val_loss: 0.7850 - val_accuracy: 0.7794\n",
      "Epoch 468/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0568 - accuracy: 0.9789 - val_loss: 1.1439 - val_accuracy: 0.7794\n",
      "Epoch 469/500\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.1153 - accuracy: 0.9494 - val_loss: 0.8401 - val_accuracy: 0.7353\n",
      "Epoch 470/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0505 - accuracy: 0.9705 - val_loss: 1.0087 - val_accuracy: 0.7647\n",
      "Epoch 471/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0531 - accuracy: 0.9789 - val_loss: 1.1394 - val_accuracy: 0.7353\n",
      "Epoch 472/500\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.1330 - accuracy: 0.9578 - val_loss: 1.0439 - val_accuracy: 0.7059\n",
      "Epoch 473/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0737 - accuracy: 0.9662 - val_loss: 1.1468 - val_accuracy: 0.7353\n",
      "Epoch 474/500\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.0784 - accuracy: 0.9578 - val_loss: 1.4693 - val_accuracy: 0.7206\n",
      "Epoch 475/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0816 - accuracy: 0.9747 - val_loss: 1.5498 - val_accuracy: 0.7206\n",
      "Epoch 476/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0520 - accuracy: 0.9831 - val_loss: 1.3152 - val_accuracy: 0.7206\n",
      "Epoch 477/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0508 - accuracy: 0.9831 - val_loss: 1.3986 - val_accuracy: 0.7206\n",
      "Epoch 478/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0285 - accuracy: 0.9873 - val_loss: 1.3044 - val_accuracy: 0.7206\n",
      "Epoch 479/500\n",
      "8/8 [==============================] - 2s 178ms/step - loss: 0.0632 - accuracy: 0.9688 - val_loss: 1.3186 - val_accuracy: 0.7206\n",
      "Epoch 480/500\n",
      "8/8 [==============================] - 2s 182ms/step - loss: 0.0782 - accuracy: 0.9688 - val_loss: 1.0754 - val_accuracy: 0.6912\n",
      "Epoch 481/500\n",
      "8/8 [==============================] - 2s 181ms/step - loss: 0.0904 - accuracy: 0.9688 - val_loss: 1.3055 - val_accuracy: 0.7500\n",
      "Epoch 482/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0854 - accuracy: 0.9536 - val_loss: 1.0886 - val_accuracy: 0.7353\n",
      "Epoch 483/500\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.0607 - accuracy: 0.9620 - val_loss: 0.7780 - val_accuracy: 0.7059\n",
      "Epoch 484/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1005 - accuracy: 0.9747 - val_loss: 0.9944 - val_accuracy: 0.7059\n",
      "Epoch 485/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0930 - accuracy: 0.9578 - val_loss: 0.8075 - val_accuracy: 0.7353\n",
      "Epoch 486/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0541 - accuracy: 0.9705 - val_loss: 0.7638 - val_accuracy: 0.7353\n",
      "Epoch 487/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0980 - accuracy: 0.9578 - val_loss: 0.6904 - val_accuracy: 0.7794\n",
      "Epoch 488/500\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.0610 - accuracy: 0.9705 - val_loss: 0.6819 - val_accuracy: 0.7941\n",
      "Epoch 489/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.1380 - accuracy: 0.9241 - val_loss: 0.5152 - val_accuracy: 0.8382\n",
      "Epoch 490/500\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 0.1114 - accuracy: 0.9747 - val_loss: 0.9433 - val_accuracy: 0.7059\n",
      "Epoch 491/500\n",
      "8/8 [==============================] - 2s 183ms/step - loss: 0.0775 - accuracy: 0.9688 - val_loss: 0.7620 - val_accuracy: 0.6912\n",
      "Epoch 492/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0550 - accuracy: 0.9705 - val_loss: 1.1195 - val_accuracy: 0.7059\n",
      "Epoch 493/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0971 - accuracy: 0.9662 - val_loss: 0.8013 - val_accuracy: 0.7941\n",
      "Epoch 494/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0992 - accuracy: 0.9705 - val_loss: 0.8726 - val_accuracy: 0.7794\n",
      "Epoch 495/500\n",
      "8/8 [==============================] - 1s 188ms/step - loss: 0.0627 - accuracy: 0.9662 - val_loss: 1.2256 - val_accuracy: 0.7353\n",
      "Epoch 496/500\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.0734 - accuracy: 0.9747 - val_loss: 1.2155 - val_accuracy: 0.7353\n",
      "Epoch 497/500\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.0399 - accuracy: 0.9916 - val_loss: 1.2510 - val_accuracy: 0.7059\n",
      "Epoch 498/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0854 - accuracy: 0.9662 - val_loss: 1.3684 - val_accuracy: 0.7206\n",
      "Epoch 499/500\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.0906 - accuracy: 0.9789 - val_loss: 1.4882 - val_accuracy: 0.7500\n",
      "Epoch 500/500\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 0.0653 - accuracy: 0.9662 - val_loss: 1.1038 - val_accuracy: 0.7353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14fef6b2c50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "model.fit(data_augmentor.flow(X_train, y_train_classes, batch_size=batch_size),\n",
    "          steps_per_epoch=len(X_train) // batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1038 - accuracy: 0.7353\n",
      "Validation Accuracy: 0.74\n",
      "Validation Loss: 1.1038\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test_classes)\n",
    "\n",
    "# Print the evaluation metrics (accuracy and loss)\n",
    "print(f\"Validation Accuracy: {evaluation[1]:.2f}\")\n",
    "print(f\"Validation Loss: {evaluation[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Fall_detect_model_0.74.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
